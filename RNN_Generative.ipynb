{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPTlvQaXKV6m+Qfr1EqB3x6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prabhsuratsingh/Recurrent-Neural-Networks/blob/master/RNN_Generative.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "klsFM4jMT2JI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "cf1ff2bd-0c0b-423b-f4b9-7f456b334a57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy pandas matplotlib torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.gutenberg.org/files/1268/1268-0.txt"
      ],
      "metadata": {
        "id": "Kzh5An8RUBcS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "992c3bbf-168a-40d7-c901-c1384916a660"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-01 17:23:29--  https://www.gutenberg.org/files/1268/1268-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1151796 (1.1M) [text/plain]\n",
            "Saving to: ‘1268-0.txt’\n",
            "\n",
            "1268-0.txt          100%[===================>]   1.10M   836KB/s    in 1.3s    \n",
            "\n",
            "2025-12-01 17:23:32 (836 KB/s) - ‘1268-0.txt’ saved [1151796/1151796]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "with open('1268-0.txt', 'r', encoding=\"utf8\") as fp:\n",
        "  text = fp.read()\n",
        "\n",
        "start_idx = text.find(\"THE MYSTERIOUS ISLAND\")\n",
        "end_idx = text.find('End of the Project Gutenberg')\n",
        "text = text[start_idx:end_idx]\n",
        "char_set = set(text)\n",
        "print(f'Total Length : {len(text)}')\n",
        "print(f'Unique Characters : {len(char_set)}')"
      ],
      "metadata": {
        "id": "Qnq5kjJ1VB3O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aff7356-b32f-40a8-b99f-4ed330f952fd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Length : 1112310\n",
            "Unique Characters : 80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars_sorted = sorted(char_set)\n",
        "char2int = {ch:i for i,ch in enumerate(chars_sorted)}\n",
        "char_array = np.array(chars_sorted)\n",
        "\n",
        "text_encoded = np.array(\n",
        "    [char2int[ch] for ch in text],\n",
        "    dtype=np.int32\n",
        ")\n",
        "\n",
        "print(f'Text Encoded shape : {text_encoded.shape}')\n",
        "\n",
        "print(text[:15], '== Encoding ==>', text_encoded[:15])\n",
        "print(text_encoded[15:21], '== Reverse ==>', ''.join(char_array[text_encoded[15:21]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZvQQVckHn1U",
        "outputId": "0f9ce45e-f674-4280-8192-4d736fb9ea8e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Encoded shape : (1112310,)\n",
            "THE MYSTERIOUS  == Encoding ==> [44 32 29  1 37 48 43 44 29 42 33 39 45 43  1]\n",
            "[33 43 36 25 38 28] == Reverse ==> ISLAND\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for ex in text_encoded[:5]:\n",
        "  print(f'{ex} -> {char_array[ex]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiGulal7KBmU",
        "outputId": "c6d36a19-8617-4557-92dd-fbbeb7b9b1a9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44 -> T\n",
            "32 -> H\n",
            "29 -> E\n",
            "1 ->  \n",
            "37 -> M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "seq_length = 40\n",
        "chunk_size = seq_length + 1\n",
        "text_chunks = [text_encoded[i:i+chunk_size] for i in range(len(text_encoded) - chunk_size + 1)]\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "  def __init__(self, text_chunks):\n",
        "    self.text_chunks = text_chunks\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.text_chunks)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    text_chunk = self.text_chunks[idx]\n",
        "    return text_chunk[:-1].long(), text_chunk[1:].long()\n",
        "\n",
        "seq_dataset = TextDataset(torch.tensor(text_chunks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byiHK7FsK_gS",
        "outputId": "993e8868-1d99-4b27-81cf-049c7931bdfd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-37180107.py:19: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n",
            "  seq_dataset = TextDataset(torch.tensor(text_chunks))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (seq, target) in enumerate(seq_dataset):\n",
        "  print(f'Input (x) : {repr(''.join(char_array[seq]))}')\n",
        "  print(f'Output (y) : {repr(''.join(char_array[target]))}')\n",
        "  print()\n",
        "  if i == 1:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmewc0cHQKR4",
        "outputId": "bd9a3399-8870-48ef-eb75-fbfdcbcfa3b9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input (x) : 'THE MYSTERIOUS ISLAND\\n\\nby Jules Verne\\n\\n1'\n",
            "Output (y) : 'HE MYSTERIOUS ISLAND\\n\\nby Jules Verne\\n\\n18'\n",
            "\n",
            "Input (x) : 'HE MYSTERIOUS ISLAND\\n\\nby Jules Verne\\n\\n18'\n",
            "Output (y) : 'E MYSTERIOUS ISLAND\\n\\nby Jules Verne\\n\\n187'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 64\n",
        "torch.manual_seed(1)\n",
        "seq_dl = DataLoader(\n",
        "    seq_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    drop_last=True\n",
        ")"
      ],
      "metadata": {
        "id": "6up8DNl1RfgV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "  def __init__(\n",
        "      self,\n",
        "      vocab_size,\n",
        "      embed_dim,\n",
        "      rnn_hidden_size\n",
        "  ):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "    self.rnn_hidden_size = rnn_hidden_size\n",
        "    self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, batch_first=True)\n",
        "    self.fc = nn.Linear(rnn_hidden_size, vocab_size)\\\n",
        "\n",
        "  def forward(self, x, hidden, cell):\n",
        "    out = self.embedding(x).unsqueeze(1)\n",
        "    out, (hidden, cell) = self.rnn(out, (hidden, cell))\n",
        "    out = self.fc(out).reshape(out.size(0), -1)\n",
        "\n",
        "    return out, hidden, cell\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "    hidden = torch.zeros(1, batch_size, self.rnn_hidden_size)\n",
        "    cell = torch.zeros(1, batch_size, self.rnn_hidden_size)\n",
        "\n",
        "    return hidden, cell"
      ],
      "metadata": {
        "id": "Pofd_UcdSTcL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(char_array)\n",
        "embed_dim = 256\n",
        "rnn_hidden_size = 512\n",
        "torch.manual_seed(1)\n",
        "\n",
        "model = RNN(vocab_size, embed_dim, rnn_hidden_size)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l28k5Z5YUSea",
        "outputId": "989c1cfd-d2b7-4b46-9a20-543952bb56c6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (embedding): Embedding(80, 256)\n",
              "  (rnn): LSTM(256, 512, batch_first=True)\n",
              "  (fc): Linear(in_features=512, out_features=80, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
      ],
      "metadata": {
        "id": "Y-nL3_iJV3vN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10000\n",
        "torch.manual_seed(1)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  hidden, cell = model.init_hidden(batch_size)\n",
        "  seq_batch, target_batch = next(iter(seq_dl))\n",
        "  optimizer.zero_grad()\n",
        "  loss = 0\n",
        "\n",
        "  for c in range(seq_length):\n",
        "    pred, hidden, cell = model(seq_batch[:, c], hidden, cell)\n",
        "    loss += loss_fn(pred, target_batch[:, c])\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  loss = loss.item() / seq_length\n",
        "  if epoch % 500 == 0:\n",
        "    print(f\"Epoch {epoch} loss: {loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTO6j6iUWDMB",
        "outputId": "3e71db8d-747d-4b59-c6d9-34abeacb3e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 loss: 2.2958\n",
            "Epoch 500 loss: 1.3883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.distributions.categorical import Categorical\n",
        "\n",
        "def sample(\n",
        "    model,\n",
        "    starting_str,\n",
        "    len_generated_text=500,\n",
        "    scale_factor=1.0\n",
        "):\n",
        "  encoded_input = torch.tensor(\n",
        "      [char2int[s] for s in starting_str]\n",
        "  )\n",
        "  encoded_input = torch.reshape(\n",
        "      encoded_input, (1, -1)\n",
        "  )\n",
        "\n",
        "  generated_str = starting_str\n",
        "\n",
        "  model.eval()\n",
        "  hidden, cell = model.init_hidden(1)\n",
        "  for c in range(len(starting_str)-1):\n",
        "    _, hidden, cell = model(\n",
        "        encoded_input[:, c].view(1), hidden, cell\n",
        "    )\n",
        "\n",
        "  last_char = encoded_input[:, -1]\n",
        "  for i in range(len_generated_text):\n",
        "    logits, hidden, cell = model(\n",
        "        last_char.view(1), hidden, cell\n",
        "    )\n",
        "    logits = torch.squeeze(logits, 0)\n",
        "    scaled_logits = logits * scale_factor\n",
        "    m = Categorical(logits=scaled_logits)\n",
        "    last_char = m.sample()\n",
        "    generated_str += str(char_array[last_char])\n",
        "\n",
        "  return generated_str"
      ],
      "metadata": {
        "id": "T4x21OHY5KnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)\n",
        "print(sample(model, starting_str='The island'))"
      ],
      "metadata": {
        "id": "Zht6vC368BSV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}